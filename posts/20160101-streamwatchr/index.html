<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!--
        for IE/Edge only
    -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="Manos Tsagkias">
    <link rel="canonical" href="https://manostsagkias.com/posts/20160101-streamwatchr/">
    <!--
        The page_title contains the title for a page as shown in the navigation.
        Site name contains the name as defined in the mkdocs.yml
    -->
    <title>Streamwatchr — Inside the world's playlist - Connecting the Dots</title>
    <!--
        Just add a favicon.ico image to the docs.
    -->
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href=../../img/apple-touch-icon.png>
    <link rel="icon" type="image/png" sizes="32x32" href=../../img/favicon-32x32.png>
    <link rel="icon" type="image/png" sizes="16x16" href=../../img/favicon-16x16.png>
    <link rel="manifest" href=/site.webmanifest>
      <link href="https://cdn.jsdelivr.net/npm/markdown-it-texmath/css/texmath.min.css" rel="stylesheet">
      <link href="https://cdn.jsdelivr.net/gh/goessner/mdmath/themes/publication/style.css" rel="stylesheet">
      <link href="../../css/custom.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alex+Brush&family=Allura&family=Dancing+Script:wght@400..700&family=Great+Vibes&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <link rel="stylesheet" href="../../css/styles.css">
    <script>
        // Inject the current file name for the active page
        const CURRENT_FILE = "posts/20160101-streamwatchr/";
    </script>
</head>
<body><div id="map-overlay" class="hidden">
    
    <button id="map-close" onclick="toggleMap()">&times;</button>
    <main>
<article>
<p>
    Hover over the dots to explore related posts. Closer dots are more semantically related, and the red dot marks the current page. 
</p>
</article>
</main>
    
    <div id="map-container"></div>
    <div id="search-container">
        <input id="search-box" type="text" placeholder="Type to search the map ..." />
    </div>    
</div>

    
    <header>
        <!-- Navigation menu -->
        
        <nav>
            <ul class="nav-bar">
                <!-- Left-aligned 'Home' link -->
                <li class="nav-left">
                    <a href="../../">Home</a>
                </li>
                
                <li class="nav-right">
                    <!-- Dynamic Navigation Items from `nav` -->
                    
                        <a href="../../about/">About</a>
                    
                    <!-- Right-aligned 'Map' link -->
                    <a href="#" onclick="toggleMap()">Map</a>
                </li>
            </ul>
        </nav>
        

        
            <h1>Streamwatchr — Inside the world's playlist</h1>


    
        <h4>Manos Tsagkias, Wouter Weerkamp, and Maarten de Rijke</h4>
    


<h5>University of Amsterdam</h5>


<h5>01 January 2016</h5>


<h5><b>Keywords:</b> social media, music, named entity linking, lyrics extraction, real-time trends</h5>

        
    </header>

    <main>
        <article>
    <h3 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h3>
<p>Streamwatchr (2013–2016), developed at the University of Amsterdam, leveraged machine learning and named entity extraction to track global music listening behavior in real time through tweets. It offered features like Top-100 charts, interactive maps, and a “radio” stream mode driven by a dynamic recommender system. Using Python and MongoDB, it processed over 438 million tweets, identified 660,941 artists, and linked them to MusicBrainz and YouTube videos. This innovative blend of analytics and entity linking earned it a spot in the Dutch delegation at South by Southwest (SXSW).</p>
<p>Streamwatchr (2013&ndash;2016) was a web application developed at the University of Amsterdam, by Wouter Weerkamp, Maarten de Rijke, and myself. Streamwatchr monitored the Twitter feed for #nowplaying, and  tracked how people interacted with songs, artists, albums, in real-time. In its latest version it also identified which parts of the lyrics were the most sung along!</p>
<p>Streamwatchr’s innovative approach earned it a place in the Dutch delegation for innovation at the internationally renowned South by Southwest (SXSW) festival.</p>
<figure>
    <a href="https://www.youtube.com/watch?v=A3qrUfRBMt4"><img src="https://img.youtube.com/vi/A3qrUfRBMt4/0.jpg" title="Video demo of Streamwatchr on YouTube."></img></a>
    <figcaption>Screencast of Streamtchr on YouTube. The video covers all the features of the platform.
    <figcaption>
</figure>

<p>Streamwatchr provided unique insights into global music listening behavior through features such as Top-100 charts, interactive maps, and a “radio” stream mode. The radio stream played a sequence of YouTube videos, with each song following the next based on the probability of them being played together. This was achieved by linking identified songs to YouTube videos and generating playlists driven by a recommender system. Behind the scenes, the system utilized a directed graph, where nodes represented songs, and edge weights encoded the likelihood of transitioning from one song to another. These weights were dynamically updated with every incoming tweet.</p>
<p>The engineering behind Streamwatchr was equally groundbreaking [<a href="#1">1</a>]. It collected music-related tweets in real time, extracted song and artist information, and mapped them to MusicBrainz, a comprehensive music database, and corresponding YouTube video clips. Every aspect of Streamwatchr, from popularity charts and trending music to song recommendations and analytics, was refreshed with each new tweet, ensuring a dynamic and up-to-date user experience.</p>
<p>Streamwatchr leveraged a tech stack of Python and MongoDB for analytics and recommendations. Its real-time capabilities were powered by efficient data structures and algorithms that minimized the computational overhead required for updates, delivering a seamless and responsive experience.</p>
<p>The millions of tweets and the hundreds of thousands of artists that Streamwatchr has listened to over the years have been distilled to a handful of noteworthy factoids:</p>
<table>
<thead>
<tr>
<th style="text-align: right;">Factoid</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right;">tweets listened</td>
<td>438,225,941</td>
</tr>
<tr>
<td style="text-align: right;">artists seen</td>
<td>660,941</td>
</tr>
<tr>
<td style="text-align: right;">most popular song</td>
<td>Passenger – Let Her Go, 196,986 times</td>
</tr>
<tr>
<td style="text-align: right;">most sung along song</td>
<td>John Legend – All of Me, 541 times</td>
</tr>
</tbody>
</table>
<h3 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h3>
<p><span id='1'/>[1]: Wouter Weerkamp, Manos Tsagkias, and Maarten de Rijke. <em>Inside the world&rsquo;s playlist</em>. In International Conference of Knowledge Management (ICKM) 2013. <a href="https://dl.acm.org/doi/abs/10.1145/2505515.2508216">ACM Library</a>; <a href="../../pdf/cikm2013-streamwatchr-demo.pdf">PDF</a></p>
</article>

<hr/>


<div class="related-links">
    <h3>Related Posts</h3>
    <ol>
        
        <li>
            
            <blockquote>
                <p>The PodCred framework is a framework for assessing the credibility and quality of podcasts published on the internet. It consists of a series of indicators designed to support prediction of listener preference of one podcast over another, given that both carry comparable informational content. The indicators are grouped into four categories pertaining to the Podcast Content, the Podcaster, the Podcast Context or the Technical Execution of the podcast. We adopt the term &ldquo;cred&rdquo; as a designation encompassing both credibility (comprising trustworthiness and expertise) and qualitative acceptability to listeners. Our podcast analysis framework is inspired by work on credibility in blogs, another medium dominated by user generated content. The PodCred framework is derived from a review of the literature on credibility for other media, a survey of prescriptive standards for podcasting, and a detailed data analysis of award winning podcasts. The paper concludes with a discussion of future work</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">19.43% similar</span>
                <span>— <a href="/posts/20081120-wicow2008-podcred/">Paper at WICOW 2008 — PodCred: A Framework for Analyzing Podcast Preference</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>Spoken audio, like any time-continuous medium, is notoriously difficult to browse or skim without support of an interface providing semantically annotated jump points to signal the user where to listen in. Creation of time-aligned metadata by human annotators is prohibitively expensive, motivating the investigation of representations of segment-level semantic content based on transcripts generated by automatic speech recognition (ASR). This paper examines the feasibility of using term clouds to provide users with a structured representation of the semantic content of podcast episodes. Podcast episodes are visualized as a series of sub-episode segments, each represented by a term cloud derived from a transcript generated by automatic speech recognition (ASR). Quality of segment-level term clouds is measured quantitatively and their utility is investigated using a small-scale user study based on human labeled segment boundaries. Since the segment-level clouds generated from</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">14.67% similar</span>
                <span>— <a href="/posts/20080720-sscs2008-speech-termclouds/">Paper at SSCS 2008 — Using Term Clouds to Represent Segment-Level Semantic Content of Podcasts</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="references">References</h3>
<p><span id="1">[1] Manos Tsagkias, Martha Larson, and Maarten Rijke. 2009. Exploiting Surface Features for the Prediction of Podcast Preference. In Proceedings of the 31th European Conference on IR Research on Advances in Information Retrieval (ECIR &lsquo;09). Springer-Verlag, Berlin, Heidelberg, 473–484. <a href="https://doi.org/10.1007/978-3-642-00958-7_42">ACM Link</a> <a href="../pdf/ecir2009-Exploiting_surface_features_for_the_pred.pdf">PDF</a></span></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">13.13% similar</span>
                <span>— <a href="/posts/20090304-ecir2009-podcred-features/">Paper at ECIR 2009 — Exploiting Surface Features for the Prediction of Podcast Preference</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>The Dutch-Belgian Information Retrieval Workshop was held this year in Delft. A nice lot of people from all around the Netherlands, Belgium, and a handful from abroad came together to share their research highlights from this year. It was a nice programme, filled with interesting short talks (about 15mins) that were great to give us a summary of what everybody is working on.</p>
<p>My personal highlight was Chato&rsquo;s keynote speech on algorithmic bias. Although a lot is discussed on the topic, there is yet no to little work that presents some sort of foundation that describes the issue, frames it and offers some theoretical framework from which we can start thinking about solutions. Chato&rsquo;s work laid the ground works on this area. He started with explaining what algorithmic bias is and stressed how coupled it is with data collection. I&rsquo;m looking forward to seeing more on his work on the subject.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">11.37% similar</span>
                <span>— <a href="/posts/20161210-dir/">Attending DIR 2016</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <figure id="__figure-caption_1">
<p><img alt="&quot;Building a Self-Learning Search Engine: From Research to Business&quot; presented at SIGIR 2016 Industry Track. Pisa, Italy." src="https://manostsagkias.wordpress.com/wp-content/uploads/2016/12/img_1843.jpg?w=1024" /></p>
<figcaption>
<p><span class="caption-prefix">Figure 1.</span> &ldquo;Building a Self-Learning Search Engine: From Research to Business&rdquo; presented at SIGIR 2016 Industry Track. Pisa, Italy.</p>
</figcaption>
</figure>
<p>This summer I was happy to be back at the Special Interest Group in Information Retrieval (SIGIR), this time, in Pisa, Italy. Last time I was at SIGIR was in Portland back in 2012, where I was presenting the work I did at Yahoo! Barcelona. SIGIR is the top international conference on search engines, and it&rsquo;s always good fun to hear the latest developments and exchange new ideas.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">10.70% similar</span>
                <span>— <a href="/posts/20161210-sigir/">Presenting at the Industry Day at SIGIR 2016</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>User generated spoken audio remains a challenge for Automatic Speech Recognition (ASR) technology and content-based audio surrogates derived from ASR-transcripts must be error robust. An investigation of the use of term clouds as surrogates for podcasts demonstrates that ASR term clouds closely approximate term clouds derived from human-generated transcripts across a range of cloud sizes. A user study confirms the conclusion that ASR-clouds are viable surrogates for depicting the content of podcasts.</p>
<h3 id="references">References</h3>
<p><span id="1">[1] Manos Tsagkias, Martha Larson, and Maarten de Rijke. 2008. <em>Term clouds as surrogates for user generated speech</em>. In Proceedings of the 31<sup>st</sup> annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR &lsquo;08). Association for Computing Machinery, New York, NY, USA, 773–774. <a href="https://doi.org/10.1145/1390334.1390497">ACM Link</a> <a href="../pdf/sigir2008-termclouds.pdf">PDF</a></span></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">10.62% similar</span>
                <span>— <a href="/posts/20080620-sigir2008-speech-termclouds/">Paper at SIGIR 2008 — Term Clouds as Surrogates for User Generated Speech</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>I&rsquo;m very happy to share news on the latest success of <a href="https://904labs.com">904Labs A.I. for Search</a> with our new customer, <a href="https://eci.nl">eci.nl</a>.</p>
<p>eci is one of the largest online book specialists in the Netherlands and Belgium, with an estimated yearly revenue of 15m euro for the Dutch part. For their site search, eci relied on a manually optimized Apache Solr, integrated into Intershop.</p>
<p>During a three-week A/B test we&rsquo;ve shown a <em>38% improvement in revenue and a 34% increase in conversion rate</em> compared to the in-house Apache Solr search engine. This shows once more that adding A.I. to your search engine really makes a difference! <a href="https://www.904labs.com/en/eci-increases-revenue-substantially-with-ai-for-search">Read the full story here.</a></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">10.27% similar</span>
                <span>— <a href="/posts/20171104-another-historical-moment-904labs/">Another historical moment for 904Labs</a></span>
            </div>
        </li>
        
    </ol>
</div>

    </main>
    
    <footer>
        <p>
            Powered by MkDocs; design follows <a href="https://github.com/goessner">Stefan Gössner</a>'s <a href="https://github.com/goessner/mdmath">md-math</a>.
        </p>
    </footer>
      <script src="https://d3js.org/d3.v7.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/dexie/dist/dexie.min.js"></script>
      <script src="../../js/d3-umap.js"></script>
      <script src="../../search/main.js"></script>
    <script type="module">
        import { search } from '/js/onnx.js';
    </script>
</body>
</html>