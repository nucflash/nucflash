<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!--
        for IE/Edge only
    -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="Manos Tsagkias">
    <link rel="canonical" href="https://manostsagkias.com/posts/20210214-icassp/">
    <!--
        The page_title contains the title for a page as shown in the navigation.
        Site name contains the name as defined in the mkdocs.yml
    -->
    <title>Paper at ICASSP 2021 — Error-driven Pruning of Language Models for Virtual Assistants - Connecting the Dots</title>
    <!--
        Just add a favicon.ico image to the docs.
    -->
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href=../../img/apple-touch-icon.png>
    <link rel="icon" type="image/png" sizes="32x32" href=../../img/favicon-32x32.png>
    <link rel="icon" type="image/png" sizes="16x16" href=../../img/favicon-16x16.png>
    <link rel="manifest" href=/site.webmanifest>
      <link href="https://cdn.jsdelivr.net/npm/markdown-it-texmath/css/texmath.min.css" rel="stylesheet">
      <link href="https://cdn.jsdelivr.net/gh/goessner/mdmath/themes/publication/style.css" rel="stylesheet">
      <link href="../../css/custom.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alex+Brush&family=Allura&family=Dancing+Script:wght@400..700&family=Great+Vibes&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <link rel="stylesheet" href="../../css/styles.css">
    <script>
        // Inject the current file name for the active page
        const CURRENT_FILE = "posts/20210214-icassp/";
    </script>
</head>
<body><div id="map-overlay" class="hidden">
    
    <button id="map-close" onclick="toggleMap()">&times;</button>
    <main>
<article>
<p>
    Hover over the dots to explore related posts. Closer dots are more semantically related, and the red dot marks the current page. 
</p>
</article>
</main>
    
    <div id="map-container"></div>
    <div id="search-container">
        <input id="search-box" type="text" placeholder="Type to search the map ..." />
    </div>    
</div>

    
    <header>
        <!-- Navigation menu -->
        
        <nav>
            <ul class="nav-bar">
                <!-- Left-aligned 'Home' link -->
                <li class="nav-left">
                    <a href="../../">Home</a>
                </li>
                
                <li class="nav-right">
                    <!-- Dynamic Navigation Items from `nav` -->
                    
                        <a href="../../about/">About</a>
                    
                    <!-- Right-aligned 'Map' link -->
                    <a href="#" onclick="toggleMap()">Map</a>
                </li>
            </ul>
        </nav>
        

        
            <h1>Paper at ICASSP 2021 — Error-driven Pruning of Language Models for Virtual Assistants</h1>


    
        <h4>Sashank Gondala, Lyan Verwimp, Ernest Pusateri, Manos Tsagkias, and Christophe van Gysel</h4>
    


<h5>Apple</h5>


<h5>14 February 2021</h5>


<h5><b>Keywords:</b> paper, conference, information retrieval, machine learning, speech, named entities</h5>

        
    </header>

    <main>
        <article>
    <h3 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h3>
<p>Language models (LMs) for virtual assistants (VAs) are typically trained on large amounts of data, resulting in prohibitively large models which require excessive memory and/or cannot be used to serve user requests in real-time. Entropy pruning results in smaller models but with significant degradation of effectiveness in the tail of the user request distribution. We customize entropy pruning by allowing for a keep list of infrequent n-grams that require a more relaxed pruning threshold, and propose three methods to construct the keep list. Each method has its own advantages and disadvantages with respect to LM size, ASR accuracy and cost of constructing the keep list. Our best LM gives 8% average Word Error Rate (WER) reduction on a targeted test set, but is 3 times larger than the baseline. We also propose discriminative methods to reduce the size of the LM while retaining the majority of the WER gains achieved by the largest LM.</p>
<p>Happy to share yet another publication with the Siri Speech team at Apple, this time led by Sashank Gondala, who interned with us last year. Our full paper<a href="https://arxiv.org/pdf/2102.07219">Error-driven Pruning of Language Models for Virtual Assistants</a> is accepted at ICASSP 2021.</p>
</article>

<hr/>


<div class="related-links">
    <h3>Related Posts</h3>
    <ol>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>We focus on improving the effectiveness of a Virtual Assistant (VA) in recognizing emerging entities in spoken queries. We introduce a method that uses historical user interactions to forecast which entities will gain in popularity and become trending, and it subse- quently integrates the predictions within the Automated Speech Recognition (ASR) component of the VA. Experiments show that our proposed approach results in a 20% relative reduction in errors on emerging entity name utterances without degrading the overall recognition quality of the system.</p>
<p>Happy to share the news about my first joint pubication with the Siri Speech team at Apple. Our short paper <a href="https://arxiv.org/abs/2005.12816">Predicting Entity Popularity to Improve Spoken Entity Recognition by Virtual Assistants</a> with Christophe van Gysel, myself, Ernie Pusateri, and Ilya Oparin, is accepted at SIGIR 2020.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">40.57% similar</span>
                <span>— <a href="/posts/20200722-sigir2020/">Paper at SIGIR 2020 — Predicting Entity Popularity to Improve Spoken Entity Recognition by Virtual Assistants</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>User generated spoken audio remains a challenge for Automatic Speech Recognition (ASR) technology and content-based audio surrogates derived from ASR-transcripts must be error robust. An investigation of the use of term clouds as surrogates for podcasts demonstrates that ASR term clouds closely approximate term clouds derived from human-generated transcripts across a range of cloud sizes. A user study confirms the conclusion that ASR-clouds are viable surrogates for depicting the content of podcasts.</p>
<h3 id="references">References</h3>
<p><span id="1">[1] Manos Tsagkias, Martha Larson, and Maarten de Rijke. 2008. <em>Term clouds as surrogates for user generated speech</em>. In Proceedings of the 31<sup>st</sup> annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR &lsquo;08). Association for Computing Machinery, New York, NY, USA, 773–774. <a href="https://doi.org/10.1145/1390334.1390497">ACM Link</a> <a href="../pdf/sigir2008-termclouds.pdf">PDF</a></span></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">23.43% similar</span>
                <span>— <a href="/posts/20080620-sigir2008-speech-termclouds/">Paper at SIGIR 2008 — Term Clouds as Surrogates for User Generated Speech</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>Our paper <em>Pseudo Test Collections for Training and Tuning Microblog Rankers</em> by Richard Berendsen, Manos Tsagkias, Maarten de Rijke, and Wouter Weerkamp [<a href="#1">1</a>] has been accepted at SIGIR 2013, in Dublin, Ireland, 28 July–1 August.</p>
<h3 id="references">References</h3>
<p><span id="1"/>[1] Richard Berendsen, Manos Tsagkias, Wouter Weerkamp, and Maarten de Rijke. 2013. <em>Pseudo test collections for training and tuning microblog rankers</em>. In Proceedings of the 36<sup>th</sup> international ACM SIGIR conference on Research and development in information retrieval (SIGIR &lsquo;13). Association for Computing Machinery, New York, NY, USA, 53–62. <a href="https://doi.org/10.1145/2484028.2484063">ACM Link</a> <a href="../pdf/sigir2013-pseudo-test-collections.pdf">PDF</a></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">23.43% similar</span>
                <span>— <a href="/posts/20130408-sigir2013-pseudo-test-collections/">Paper at SIGIR 2013 — Pseudo Test Collections for Training and Tuning Microblog Rankers</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>I moved to Barcelona in the first week of September for a three-month internship at Yahoo! Research Labs. I’m very excited about it, and I&rsquo;m looking forward to getting to know the people here and the problems they are working on.</p>
<p>Update: My work at Yahoo! Research Labs resulted in a publication at SIGIR 2012 [<a href="#1">1</a>]; see [post] for the abstract(20120623-sigir2012-language-intent-models.md).</p>
<h3 id="references">References</h3>
<p><span id="1"/>[1] Manos Tsagkias and Roi Blanco. 2012. <em>Language intent models for inferring user browsing behavior</em>. In Proceedings of the 35<sup>th</sup> international ACM SIGIR conference on research and development in information retrieval (SIGIR &lsquo;12). Association for Computing Machinery, New York, NY, USA, 335–344. <a href="https://doi.org/10.1145/2348283.2348330">ACM Link</a>. <a href="../pdf/sigir2012-Language_Intent_Models_for_Inferring_Use.pdf">PDF</a></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">18.19% similar</span>
                <span>— <a href="/posts/20110914-yahoo-research/">Internship at Yahoo! Research Labs</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="short-bio">Short bio</h3>
<p>I design scalable systems for speech, search, recommendation, and predictive analytics, combining theory with elegant engineering to enhance user experiences. With a Ph.D. in Machine Learning and a strong foundation in Physics, I have founded three companies: MyYard, the first cloud-based ERP system for the waste management industry; 904Labs, the world’s first self-learning product search engine offered as a service; and Solumbro, which introduced the first solar-powered umbrella with a virtual assistant. As an academic, my research has earned an H-index of 20, with over 55 published papers. I have co-supervised a Ph.D. thesis and guided more than 10 master’s theses. Currently, I’m an R&amp;D Engineer at Apple, tackling virtual assistants at the challenging intersection of speech and search.</p>
<div class="toc">
<ul>
<li><a href="#short-bio">Short bio</a></li>
<li><a href="#highlights">Highlights</a><ul>
<li><a href="#904labs-self-learning-search-engine">904Labs self-learning search engine</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="highlights">Highlights</h2>
<h3 id="904labs-self-learning-search-engine">904Labs self-learning search engine</h3>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">18.07% similar</span>
                <span>— <a href="/about/">About</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>Since the segment-level clouds generated from ASR-transcripts prove useful, we examine an adaptation of text tiling techniques to speech in order to be able to generate segments as part of a completely automated indexing and structuring system for browsing of spoken audio. Results demonstrate that the segments generated are comparable with human selected segment boundaries.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">17.95% similar</span>
                <span>— <a href="/posts/20080720-sscs2008-speech-termclouds/">Paper at SSCS 2008 — Using Term Clouds to Represent Segment-Level Semantic Content of Podcasts</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>I took part in SIREN 2008, a research event in the Netherlands, presenting our work with Martha Larson and Maarten de Rijke, on <em>Term Clouds as Surrogates for User Generated Speech</em> [<a href="#1">1</a>]; see <a href="20080620-sigir2008-speech-termclouds.md">post</a></p>
<h3 id="references">References</h3>
<p><span id="1">[1] Manos Tsagkias, Martha Larson, and Maarten de Rijke. 2008. <em>Term clouds as surrogates for user generated speech</em>. In Proceedings of the 31<sup>st</sup> annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR &lsquo;08). Association for Computing Machinery, New York, NY, USA, 773–774. <a href="https://doi.org/10.1145/1390334.1390497">ACM Link</a> <a href="../pdf/sigir2008-termclouds.pdf">PDF</a></span></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">17.77% similar</span>
                <span>— <a href="/posts/20081202-siren2008-talk-speech-termclouds/">Talk at SIREN 2008 on Speech Term Clouds</a></span>
            </div>
        </li>
        
    </ol>
</div>

    </main>
    
    <footer>
        <p>
            Powered by MkDocs; design follows <a href="https://github.com/goessner">Stefan Gössner</a>'s <a href="https://github.com/goessner/mdmath">md-math</a>.
        </p>
    </footer>
      <script src="https://d3js.org/d3.v7.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/dexie/dist/dexie.min.js"></script>
      <script src="../../js/d3-umap.js"></script>
      <script src="../../search/main.js"></script>
    <script type="module">
        import { search } from '/js/onnx.js';
    </script>
</body>
</html>