<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!--
        for IE/Edge only
    -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="Manos Tsagkias">
    <link rel="canonical" href="https://manostsagkias.com/posts/20130408-sigir2013-pseudo-test-collections/">
    <!--
        The page_title contains the title for a page as shown in the navigation.
        Site name contains the name as defined in the mkdocs.yml
    -->
    <title>Paper at SIGIR 2013 — Pseudo Test Collections for Training and Tuning Microblog Rankers - Connecting the Dots</title>
    <!--
        Just add a favicon.ico image to the docs.
    -->
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href=../../img/apple-touch-icon.png>
    <link rel="icon" type="image/png" sizes="32x32" href=../../img/favicon-32x32.png>
    <link rel="icon" type="image/png" sizes="16x16" href=../../img/favicon-16x16.png>
    <link rel="manifest" href=/site.webmanifest>
      <link href="https://cdn.jsdelivr.net/npm/markdown-it-texmath/css/texmath.min.css" rel="stylesheet">
      <link href="https://cdn.jsdelivr.net/gh/goessner/mdmath/themes/publication/style.css" rel="stylesheet">
      <link href="../../css/custom.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alex+Brush&family=Allura&family=Dancing+Script:wght@400..700&family=Great+Vibes&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <link rel="stylesheet" href="../../css/styles.css">
    <script>
        // Inject the current file name for the active page
        const CURRENT_FILE = "posts/20130408-sigir2013-pseudo-test-collections/";
    </script>
</head>
<body><div id="map-overlay" class="hidden">
    
    <button id="map-close" onclick="toggleMap()">&times;</button>
    <main>
<article>
<p>
    Hover over the dots to explore related posts. Closer dots are more semantically related, and the red dot marks the current page. 
</p>
</article>
</main>
    
    <div id="map-container"></div>
    <div id="search-container">
        <input id="search-box" type="text" placeholder="Type to search the map ..." />
    </div>    
</div>

    
    <header>
        <!-- Navigation menu -->
        
        <nav>
            <ul class="nav-bar">
                <!-- Left-aligned 'Home' link -->
                <li class="nav-left">
                    <a href="../../">Home</a>
                </li>
                
                <li class="nav-right">
                    <!-- Dynamic Navigation Items from `nav` -->
                    
                        <a href="../../about/">About</a>
                    
                    <!-- Right-aligned 'Map' link -->
                    <a href="#" onclick="toggleMap()">Map</a>
                </li>
            </ul>
        </nav>
        

        
            <h1>Paper at SIGIR 2013 — Pseudo Test Collections for Training and Tuning Microblog Rankers</h1>


    
        <h4>Richard Berendsen, Manos Tsagkias, Wouter Weerkamp, and Maarten de Rijke</h4>
    


<h5>University of Amsterdam</h5>


<h5>08 April 2013</h5>


<h5><b>Keywords:</b> paper, sigir</h5>

        
    </header>

    <main>
        <article>
    <h3 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h3>
<p>Recent years have witnessed a persistent interest in generating pseudo test collections, both for training and evaluation purposes. We describe a method for generating queries and relevance judgments for microblog search in an unsupervised way. Our starting point is this intuition: tweets with a hashtag are relevant to the topic covered by the hashtag and hence to a suitable query derived from the hashtag. Our baseline method selects all commonly used hashtags, and all associated tweets as relevance judgments; we then generate a query from these tweets. Next, we generate a timestamp for each query, allowing us to use temporal information in the training process. We then enrich the generation process with knowledge derived from an editorial test collection for microblog search.
&nbsp;
We use our pseudo test collections in two ways. First, we tune parameters of a variety of well known retrieval methods on them. Correlations with parameter sweeps on an editorial test collection are high on average, with a large variance over retrieval algorithms. Second, we use the pseudo test collections as training sets in a learning to rank scenario. Performance close to the training error on the editorial collection is achieved in all cases. Our results demonstrate the utility of tuning and training microblog search retrieval algorithms on automatically generated training material.</p>
<p>Our paper <em>Pseudo Test Collections for Training and Tuning Microblog Rankers</em> by Richard Berendsen, Manos Tsagkias, Maarten de Rijke, and Wouter Weerkamp [<a href="#1">1</a>] has been accepted at SIGIR 2013, in Dublin, Ireland, 28 July–1 August.</p>
<h3 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h3>
<p><span id="1"/>[1] Richard Berendsen, Manos Tsagkias, Wouter Weerkamp, and Maarten de Rijke. 2013. <em>Pseudo test collections for training and tuning microblog rankers</em>. In Proceedings of the 36<sup>th</sup> international ACM SIGIR conference on Research and development in information retrieval (SIGIR &lsquo;13). Association for Computing Machinery, New York, NY, USA, 53–62. <a href="https://doi.org/10.1145/2484028.2484063">ACM Link</a> <a href="../../pdf/sigir2013-pseudo-test-collections.pdf">PDF</a></p>
</article>

<hr/>


<div class="related-links">
    <h3>Related Posts</h3>
    <ol>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>We propose a retrieval model for searching microblog posts for a given topic of interest. We develop a language modeling approach tailored to microblogging characteristics, where redundancy-based IR methods cannot be used in a straightforward manner. We enhance this model with two groups of quality indicators: textual and microblog specific. Additionally, we propose a dynamic query expansion model for microblog post retrieval. Experimental results on Twitter data reveal the usefulness of boolean search, and demonstrate the utility of quality indicators and query expansion in microblog search.</p>
<h3 id="references">References</h3>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">33.11% similar</span>
                <span>— <a href="/posts/20110119-ecir2011-query-expansion/">Paper at ECIR 2011 — Incorporating Query Expansion and Quality Indicators in Searching Microblog Posts</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>Offering access to information in microblog posts requires successful language identification. Language identification on sparse and noisy data can be challenging. In this paper we explore the performance of a state-of-the-art n-gram-based language identifier, and we introduce two semi-supervised priors to enhance performance at microblog post level: (i) blogger-basedprior, using previous posts by the same blogger, and (ii) link-based prior, using the pages linked to from the post. We test our models on five languages (Dutch, English, French, German, and Spanish), and a set of 1,000 tweets per language. Results show that our priors improve accuracy, but that there is still room for improvement.</p>
<h3 id="references">References</h3>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">31.03% similar</span>
                <span>— <a href="/posts/20110120-dir2011-language-identification/">Paper at DIR 2011 — Semi-Supervised Priors for Microblog Language Identification</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>This year I talked at the industry track where I shared my experiences from running a search startup in the Netherlands. I received positive feedback, and it was good to catch up with old friends and meet new people. If you want a <a href="https://www.904labs.com/2016/08/05/904labs-sigir-2016/">short recap from the latest and greatest trends in search technology, read on my summary on 904Labs blog</a>.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">19.56% similar</span>
                <span>— <a href="/posts/20161210-sigir/">Presenting at the Industry Day at SIGIR 2016</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>Last, an extra tip: we found that boolean scoring may be on par or outperform tf.idf or BM25 scoring in the e-commerce domain, it&rsquo;s worth checking its effectiveness on your own data ;)</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">17.66% similar</span>
                <span>— <a href="/posts/20190718-ecommerce-workshop/">Inlieu of an Invited Talk—Thoughts on the Future of Search in E-commerce</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>As eCommerce is becoming increasingly important, we recruited a small team of researchers from major and not so major players in the field to share views and experiences on theoretical and practical challenges and future directions on eCommerce search and recommendations. The result of our effort, <a href="http://sigir.org/wp-content/uploads/2020/06/p04.pdf">Challenges and Research Opportunities in eCommerce Search and Recommendations</a> is published in <a href="http://sigir.org/forum/issues/june-2020/">June 2020 issue of SIGIR Forum</a>.</p>
<p>This work is related to <a href="20190718-ecommerce-workshop.md">thoughts that I shared earlier on product search</a>, and to <a href="20180618-query-engine.md">904Labs&rsquo; Query Intent engine</a> and its <a href="20180618-query-engine-upgrade.md">magnificent results (examples)</a>.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">16.47% similar</span>
                <span>— <a href="/posts/20200622-sigir-forum-ecommerce/">Paper on eCommerce at SIGIR Forum — Challenges and Research Opportunities in eCommerce Search and Recommendations</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>Modeling user browsing behavior is an active research area with
tangible real-world applications, e.g., organizations can adapt
their online presence to their visitors browsing behavior with
positive effects in user engagement, and revenue. We concentrate on
online news agents, and present a semi-supervised method for
predicting news articles that a user will visit after reading an
initial article. Our method tackles the problem using language
intent models trained on historical data which can cope
with unseen articles. We evaluate our method on a large set of
articles and in several experimental settings. Our results
demonstrate the utility of language intent models for predicting
user browsing behavior within online news sites.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">14.24% similar</span>
                <span>— <a href="/posts/20120623-sigir2012-language-intent-models/">Paper at SIGIR 2012 — Language Intent Models for Inferring User Browsing Behavior</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>Language models (LMs) for virtual assistants (VAs) are typically trained on large amounts of data, resulting in prohibitively large models which require excessive memory and/or cannot be used to serve user requests in real-time. Entropy pruning results in smaller models but with significant degradation of effectiveness in the tail of the user request distribution. We customize entropy pruning by allowing for a keep list of infrequent n-grams that require a more relaxed pruning threshold, and propose three methods to construct the keep list. Each method has its own advantages and disadvantages with respect to LM size, ASR accuracy and cost of constructing the keep list. Our best LM gives 8% average Word Error Rate (WER) reduction on a targeted test set, but is 3 times larger than the baseline. We also propose discriminative methods to reduce the size of the LM while retaining the majority of the WER gains achieved by the largest LM.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">13.18% similar</span>
                <span>— <a href="/posts/20210214-icassp/">Paper at ICASSP 2021 — Error-driven Pruning of Language Models for Virtual Assistants</a></span>
            </div>
        </li>
        
    </ol>
</div>

    </main>
    
    <footer>
        <p>
            Powered by MkDocs; design follows <a href="https://github.com/goessner">Stefan Gössner</a>'s <a href="https://github.com/goessner/mdmath">md-math</a>.
        </p>
    </footer>
      <script src="https://d3js.org/d3.v7.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/dexie/dist/dexie.min.js"></script>
      <script src="../../js/d3-umap.js"></script>
      <script src="../../search/main.js"></script>
    <script type="module">
        import { search } from '/js/onnx.js';
    </script>
</body>
</html>