<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!--
        for IE/Edge only
    -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="Manos Tsagkias">
    <link rel="canonical" href="https://manostsagkias.com/posts/20210214-icassp/">
    <!--
        The page_title contains the title for a page as shown in the navigation.
        Site name contains the name as defined in the mkdocs.yml
    -->
    <title>Paper at ICASSP 2021 — Error-driven Pruning of Language Models for Virtual Assistants - Connecting the Dots</title>
    <!--
        Just add a favicon.ico image to the docs.
    -->
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href=../../img/apple-touch-icon.png>
    <link rel="icon" type="image/png" sizes="32x32" href=../../img/favicon-32x32.png>
    <link rel="icon" type="image/png" sizes="16x16" href=../../img/favicon-16x16.png>
    <link rel="manifest" href=/site.webmanifest>
      <link href="https://cdn.jsdelivr.net/npm/markdown-it-texmath/css/texmath.min.css" rel="stylesheet">
      <link href="https://cdn.jsdelivr.net/gh/goessner/mdmath/themes/publication/style.css" rel="stylesheet">
      <link href="../../css/custom.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alex+Brush&family=Allura&family=Dancing+Script:wght@400..700&family=Great+Vibes&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <link rel="stylesheet" href="../../css/styles.css">
    <script>
        // Inject the current file name for the active page
        const CURRENT_FILE = "posts/20210214-icassp/";
    </script>
</head>
<body><div id="map-overlay" class="hidden">
    
    <button id="map-close" onclick="toggleMap()">&times;</button>
    <main>
<article>
<p>
    Hover over the dots to explore related posts. Closer dots are more semantically related, and the red dot marks the current page. 
</p>
</article>
</main>
    
    <div id="map-container"></div>
    <div id="search-container">
        <input id="search-box" type="text" placeholder="Type to search the map ..." />
    </div>    
</div>

    
    <header>
        <!-- Navigation menu -->
        
        <nav>
            <ul class="nav-bar">
                <!-- Left-aligned 'Home' link -->
                <li class="nav-left">
                    <a href="../../">Home</a>
                </li>
                
                <li class="nav-right">
                    <!-- Dynamic Navigation Items from `nav` -->
                    
                        <a href="../../about/">About</a>
                    
                    <!-- Right-aligned 'Map' link -->
                    <a href="#" onclick="toggleMap()">Map</a>
                </li>
            </ul>
        </nav>
        

        
            <h1>Paper at ICASSP 2021 — Error-driven Pruning of Language Models for Virtual Assistants</h1>


    
        <h4>Sashank Gondala, Lyan Verwimp, Ernest Pusateri, Manos Tsagkias, and Christophe van Gysel</h4>
    


<h5>Apple</h5>


<h5>14 February 2021</h5>


<h5><b>Keywords:</b> paper, conference, information retrieval, machine learning, speech, named entities</h5>

        
    </header>

    <main>
        <article>
    <h3 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h3>
<p>Language models (LMs) for virtual assistants (VAs) are typically trained on large amounts of data, resulting in prohibitively large models which require excessive memory and/or cannot be used to serve user requests in real-time. Entropy pruning results in smaller models but with significant degradation of effectiveness in the tail of the user request distribution. We customize entropy pruning by allowing for a keep list of infrequent n-grams that require a more relaxed pruning threshold, and propose three methods to construct the keep list. Each method has its own advantages and disadvantages with respect to LM size, ASR accuracy and cost of constructing the keep list. Our best LM gives 8% average Word Error Rate (WER) reduction on a targeted test set, but is 3 times larger than the baseline. We also propose discriminative methods to reduce the size of the LM while retaining the majority of the WER gains achieved by the largest LM.</p>
<p>Happy to share yet another publication with the Siri Speech team at Apple, this time led by Sashank Gondala, who interned with us last year. Our full paper<a href="https://arxiv.org/pdf/2102.07219">Error-driven Pruning of Language Models for Virtual Assistants</a> is accepted at ICASSP 2021.</p>
</article>

<hr/>


<div class="related-links">
    <h3>Related Posts</h3>
    <ol>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>We focus on improving the effectiveness of a Virtual Assistant (VA) in recognizing emerging entities in spoken queries. We introduce a method that uses historical user interactions to forecast which entities will gain in popularity and become trending, and it subse- quently integrates the predictions within the Automated Speech Recognition (ASR) component of the VA. Experiments show that our proposed approach results in a 20% relative reduction in errors on emerging entity name utterances without degrading the overall recognition quality of the system.</p>
<p>Happy to share the news about my first joint pubication with the Siri Speech team at Apple. Our short paper <a href="https://arxiv.org/abs/2005.12816">Predicting Entity Popularity to Improve Spoken Entity Recognition by Virtual Assistants</a> with Christophe van Gysel, myself, Ernie Pusateri, and Ilya Oparin, is accepted at SIGIR 2020.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">40.56% similar</span>
                <span>— <a href="/posts/20200722-sigir2020/">Paper at SIGIR 2020 — Predicting Entity Popularity to Improve Spoken Entity Recognition by Virtual Assistants</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <p>Spoken audio, like any time-continuous medium, is notoriously difficult to browse or skim without support of an interface providing semantically annotated jump points to signal the user where to listen in. Creation of time-aligned metadata by human annotators is prohibitively expensive, motivating the investigation of representations of segment-level semantic content based on transcripts generated by automatic speech recognition (ASR). This paper examines the feasibility of using term clouds to provide users with a structured representation of the semantic content of podcast episodes. Podcast episodes are visualized as a series of sub-episode segments, each represented by a term cloud derived from a transcript generated by automatic speech recognition (ASR). Quality of segment-level term clouds is measured quantitatively and their utility is investigated using a small-scale user study based on human labeled segment boundaries. Since the segment-level clouds generated from</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">24.15% similar</span>
                <span>— <a href="/posts/20080720-sscs2008-speech-termclouds/">Paper at SSCS 2008 — Using Term Clouds to Represent Segment-Level Semantic Content of Podcasts</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>Modeling user browsing behavior is an active research area with
tangible real-world applications, e.g., organizations can adapt
their online presence to their visitors browsing behavior with
positive effects in user engagement, and revenue. We concentrate on
online news agents, and present a semi-supervised method for
predicting news articles that a user will visit after reading an
initial article. Our method tackles the problem using language
intent models trained on historical data which can cope
with unseen articles. We evaluate our method on a large set of
articles and in several experimental settings. Our results
demonstrate the utility of language intent models for predicting
user browsing behavior within online news sites.</p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">23.22% similar</span>
                <span>— <a href="/posts/20120623-sigir2012-language-intent-models/">Paper at SIGIR 2012 — Language Intent Models for Inferring User Browsing Behavior</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="short-bio">Short bio</h3>
<p>I design scalable systems for speech, search, recommendation, and predictive analytics, combining theory with elegant engineering to enhance user experiences. With a Ph.D. in Machine Learning and a strong foundation in Physics, I have founded three companies: MyYard, the first cloud-based ERP system for the waste management industry; 904Labs, the world’s first self-learning product search engine offered as a service; and Solumbro, which introduced the first solar-powered umbrella with a virtual assistant. As an academic, my research has earned an H-index of 20, with over 55 published papers. I have co-supervised a Ph.D. thesis and guided more than 10 master’s theses. Currently, I’m an R&amp;D Engineer at Apple, tackling virtual assistants at the challenging intersection of speech and search.</p>
<div class="toc">
<ul>
<li><a href="#short-bio">Short bio</a></li>
<li><a href="#highlights">Highlights</a><ul>
<li><a href="#904labs-self-learning-search-engine">904Labs self-learning search engine</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="highlights">Highlights</h2>
<h3 id="904labs-self-learning-search-engine">904Labs self-learning search engine</h3>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">20.63% similar</span>
                <span>— <a href="/about/">About</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>Offering access to information in microblog posts requires successful language identification. Language identification on sparse and noisy data can be challenging. In this paper we explore the performance of a state-of-the-art n-gram-based language identifier, and we introduce two semi-supervised priors to enhance performance at microblog post level: (i) blogger-basedprior, using previous posts by the same blogger, and (ii) link-based prior, using the pages linked to from the post. We test our models on five languages (Dutch, English, French, German, and Spanish), and a set of 1,000 tweets per language. Results show that our priors improve accuracy, but that there is still room for improvement.</p>
<h3 id="references">References</h3>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">20.06% similar</span>
                <span>— <a href="/posts/20110120-dir2011-language-identification/">Paper at DIR 2011 — Semi-Supervised Priors for Microblog Language Identification</a></span>
            </div>
        </li>
        
        <li>
            
            <blockquote>
                <h3 id="abstract">Abstract</h3>
<p>User generated spoken audio remains a challenge for Automatic Speech Recognition (ASR) technology and content-based audio surrogates derived from ASR-transcripts must be error robust. An investigation of the use of term clouds as surrogates for podcasts demonstrates that ASR term clouds closely approximate term clouds derived from human-generated transcripts across a range of cloud sizes. A user study confirms the conclusion that ASR-clouds are viable surrogates for depicting the content of podcasts.</p>
<h3 id="references">References</h3>
<p><span id="1">[1] Manos Tsagkias, Martha Larson, and Maarten de Rijke. 2008. <em>Term clouds as surrogates for user generated speech</em>. In Proceedings of the 31<sup>st</sup> annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR &lsquo;08). Association for Computing Machinery, New York, NY, USA, 773–774. <a href="https://doi.org/10.1145/1390334.1390497">ACM Link</a> <a href="../pdf/sigir2008-termclouds.pdf">PDF</a></span></p>
            </blockquote>
            
            <div class="snippet-meta">
                <span class="score">17.75% similar</span>
                <span>— <a href="/posts/20080620-sigir2008-speech-termclouds/">Paper at SIGIR 2008 — Term Clouds as Surrogates for User Generated Speech</a></span>
            </div>
        </li>
        
    </ol>
</div>

    </main>
    
    <footer>
        <p>
            Powered by MkDocs; design follows <a href="https://github.com/goessner">Stefan Gössner</a>'s <a href="https://github.com/goessner/mdmath">md-math</a>.
        </p>
    </footer>
      <script src="https://d3js.org/d3.v7.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/dexie/dist/dexie.min.js"></script>
      <script src="../../js/d3-umap.js"></script>
      <script src="../../search/main.js"></script>
    <script type="module">
        import { search } from '/js/onnx.js';
    </script>
</body>
</html>